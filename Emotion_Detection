from keras.preprocessing.image import ImageDataGenerator
#Loading the images and data augmentation(Data augmentation 
# is a technique of artificially increasing the training 
# set by creating modified copies of a dataset using 
# existing data)#rotation,rescaling,horizontal,change 
# it's position etc
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten
#Flatten is the function that converts the pooled feature 
# map to a single column that is passed to the fully 
# connected layer
from keras.layers import Conv2D,MaxPooling2D
#2D
import os
#to import images in folder
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
from google.colab.patches import cv2_imshow


#image height and width=48 batch size=32
train_data_dir='/content/drive/MyDrive/Facial Emotion Recognition/train'
validation_data_dir='/content/drive/MyDrive/Facial Emotion Recognition/test'

print("Image loading.....")
train_datagen=ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

validation_datagen=ImageDataGenerator(rescale=1./255)
#flow_from_directory-Takes the path to a directory & generates batches of 
# augmented data.
train_generator=train_datagen.flow_from_directory(
    train_data_dir,#directory
    color_mode='grayscale',
    target_size=(48,48),
    batch_size=32,
    #while loading images from folder takes 32 images 
    # in one batch
    class_mode='categorical',
    #seven category present not binary classifier
    shuffle=True
)

validation_generator=validation_datagen.flow_from_directory(
    validation_data_dir,#directory
    color_mode='grayscale',
    target_size=(48,48),
    batch_size=32,
    #while loading images from folder takes 32 images 
    # in one batch
    class_mode='categorical',
    #seven category present not binary classifier
    shuffle=True
)
print(validation_generator)
class_labels=['Angry','Disgust','Fear','Happy','Neutral',
'Sad','Surprise']

img, label=train_generator.__next__()
#angry-0....

model=Sequential()#training in sequence
#input layer
model.add(Conv2D(32, kernel_size=(3,3),activation='relu',
input_shape=(48,48,1)))#48by48 greyscale so 1 not rgb(3)
#3by3 filter (32)

#2 hidden layers for computation
model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.1))
#Dropout of 0.1 means deactivation of 0.1 neurons to avoid underfiiting or 
# overfitting problem

model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.1))

model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.1))

model.add(Flatten())#in single column
model.add(Dense(512,activation='relu'))#512 features
model.add(Dropout(0.2))

#output layer
model.add(Dense(7,activation='softmax'))

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
print(model.summary())

train_path="/content/drive/MyDrive/Facial Emotion Recognition/train"
test_path="/content/drive/MyDrive/Facial Emotion Recognition/test"

#counting total number of files in the test and train folder
num_train_imgs=0
for root,dirs,files in os.walk(train_path):
    num_train_imgs+=len(files)

num_test_imgs=0
for root,dirs,files in os.walk(test_path):
    num_test_imgs+=len(files)

print(num_train_imgs,num_test_imgs)
epochs=1

history=model.fit(train_generator,steps_per_epoch=num_train_imgs//32,
epochs=epochs,validation_data=validation_generator,validation_steps=num_test_imgs//32
)
# # validation_steps is the number of steps(batches of samples) to evaluate model against the dataset. Any number smaller than the total number of batches of the evaluation dataset should be okay.
model.save('/content/drive/MyDrive/Facial Emotion Recognition/model_file_30epochs.h5')#save in this folder


import cv2
import numpy as np
from keras.models import load_model

model=load_model('model_file_30epochs.h5')

faceDetect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

labels_dict={0:"Angry",1:"Disgust", 2: "Fear", 3:"Happy",4:"Neutral",5:"Sad",6:"Surprise"}

#len(number_of_Image), image height, image width, channel

frame=cv2.imread("PrivateTest_166793.jpg")

gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

faces=faceDetect.detectMultiScale(gray, 1.3, 3) 
for x,y,w,h in faces:
  sub_face_img=gray[y:y+h, x:x+w] 
  resized=cv2.resize(sub_face_img, (48,48))
  normalize=resized/255.0
  reshaped=np.reshape(normalize, (1, 48, 48, 1)) 
  result=model.predict(reshaped)
  label=np.argmax(result, axis=1)[0]
  print(label)
  cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255),1)
  cv2.rectangle(frame, (x,y), (x+w, y+h), (50,50,255),2)
  cv2.rectangle(frame, (x,y-40), (x+w, y), (50,50,255),-1)
  cv2.putText(frame, labels_dict[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255),2)

cv2_imshow(frame)